Model Name,Model Type,Fine-Tuned Goal,Date Fine-Tuned,Dataset Description,Success Criteria,Model Architecture,Learning Rate,Batch Size,Num Epochs,Training Dataset,Fine-Tuning Script,Training Duration (hours),Hardware Used,WandB Link
llama 2,LLM,question generation on sociology,2023-11-05,A dataset of sociology flashcards,Achieve a question generation accuracy of 90% or higher for sociology,GPT-3.5,0.001,64,5,question_generation_dataset_v2.csv,fine_tune.py,9,2X80GB Vast.ai cloud GPU,https://wandb.ai/username/llama-2-fine-tuning
llama 2,LLM,question generation on psychology,2023-11-05,A dataset of psychology flashcards,Achieve a question generation accuracy of 90% or higher for psychology,GPT-3.5,0.001,64,3,question_generation_dataset_v1.csv,fine_tune.py,24,1X80GB Vast.ai cloud GPU,https://wandb.ai/username/llama-2-fine-tuning
